import Foundation
import AVFoundation
import ScreenCaptureKit
import CoreMedia

// LoggingService for unified logging  
private let logger = LoggingService.shared

// MARK: - Timeout Wrapper

/// Executa uma opera√ß√£o ass√≠ncrona com timeout
func withTimeout<T>(seconds: TimeInterval, operation: @escaping () async throws -> T) async throws -> T {
    return try await withThrowingTaskGroup(of: T.self) { group in
        group.addTask {
            try await operation()
        }
        
        group.addTask {
            try await Task.sleep(nanoseconds: UInt64(seconds * 1_000_000_000))
            throw ScreenCaptureKitError.configurationFailed
        }
        
        guard let result = try await group.next() else {
            throw ScreenCaptureKitError.configurationFailed
        }
        
        group.cancelAll()
        return result
    }
}

// MARK: - Pipeline ScreenCaptureKit

/// Pipeline para captura de √°udio do sistema usando ScreenCaptureKit (macOS 13.0+)
@available(macOS 13.0, *)
class ScreenCaptureKitAudioPipeline: NSObject, SCStreamDelegate, SCStreamOutput, SystemAudioCaptureProtocol {
    private var stream: SCStream?
    private var _isCapturing = false
    private var _isPaused = false
    
    // üîß DIAGN√ìSTICO: Contadores para debug
    private var audioSamplesReceived = 0
    private var lastSampleTime = Date()
    private var streamStartTime = Date()
    private var logFile: FileHandle?
    
    // MARK: - AudioCaptureProtocol Properties
    
    var onAudioReceived: ((AVAudioPCMBuffer, UInt64) -> Void)?
    var onStreamFailure: ((Error) -> Void)?
    
    var isCapturing: Bool { _isCapturing }
    var isPaused: Bool { _isPaused }
    
    // MARK: - SystemAudioCaptureProtocol Properties
    
    var isSystemAudioSupported: Bool {
        let osVersion = ProcessInfo.processInfo.operatingSystemVersion
        return osVersion.majorVersion >= 13
    }
    
    // Legacy property para compatibilidade
    var onSystemAudioReceived: ((AVAudioPCMBuffer, UInt64) -> Void)? {
        get { onAudioReceived }
        set { onAudioReceived = newValue }
    }
    
    // MARK: - AudioCaptureProtocol Methods
    
    func startCapture(configuration: AudioConfiguration) async throws {
        logger.info("üé¨ Iniciando captura ScreenCaptureKit...")
        
        // üîß DIAGN√ìSTICO: Resetar contadores e iniciar log detalhado
        audioSamplesReceived = 0
        streamStartTime = Date()
        lastSampleTime = Date()
        
        // Criar arquivo de log espec√≠fico para esta sess√£o
        setupDebugLogging()
        
        // üîß DIAGN√ìSTICO: Log detalhado da configura√ß√£o
        logger.debug("üîç DIAGN√ìSTICO - ScreenCaptureKit startCapture:")
        logger.debug("   ‚Ä¢ Estrat√©gia: \(configuration.captureStrategy)")
        logger.debug("   ‚Ä¢ Sample Rate: \(configuration.sampleRate)Hz")
        logger.debug("   ‚Ä¢ Canais: \(configuration.channels)")
        logger.debug("   ‚Ä¢ systemAudioConfig: \(configuration.systemAudioConfig != nil ? "‚úÖ" : "‚ùå")")
        
        guard isSystemAudioSupported else {
            logger.error("Sistema n√£o suporta ScreenCaptureKit")
            throw SystemAudioCaptureError.systemVersionNotSupported
        }
        
        guard await requestSystemPermissions() else {
            logger.error("Permiss√µes de ScreenCaptureKit negadas")
            throw SystemAudioCaptureError.permissionDenied
        }
        
        logger.debug("üîç Obtendo conte√∫do compartilh√°vel...")
        let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
        
        guard let display = content.displays.first else {
            logger.error("Nenhum display encontrado")
            throw SystemAudioCaptureError.noDisplayFound
        }
        
        logger.debug("üîç Display encontrado: \(display.width)x\(display.height)")
        
        let filter = SCContentFilter(display: display, excludingApplications: [], exceptingWindows: [])
        
        let config = SCStreamConfiguration()
        config.capturesAudio = true
        config.excludesCurrentProcessAudio = configuration.systemAudioConfig?.excludeCurrentProcess ?? true
        config.sampleRate = Int(configuration.sampleRate)
        config.channelCount = Int(configuration.channels)
        
        // üîß CONFIGURA√á√ïES OTIMIZADAS baseadas na pesquisa para estabilidade
        // Configura√ß√£o m√≠nima de captura de tela para reduzir overhead
        config.width = 2  // Captura m√≠nima conforme sugerido na pesquisa
        config.height = 2
        config.minimumFrameInterval = CMTime(value: 1, timescale: 1) // 1 FPS m√≠nimo
        config.showsCursor = false
        config.scalesToFit = false
        
        // üîß DIAGN√ìSTICO: Log da configura√ß√£o do SCStream
        logger.debug("üîç Configura√ß√£o SCStream:")
        logger.debug("   ‚Ä¢ capturesAudio: \(config.capturesAudio)")
        logger.debug("   ‚Ä¢ excludesCurrentProcessAudio: \(config.excludesCurrentProcessAudio)")
        logger.debug("   ‚Ä¢ sampleRate: \(config.sampleRate)")
        logger.debug("   ‚Ä¢ channelCount: \(config.channelCount)")
        
        stream = SCStream(filter: filter, configuration: config, delegate: self)
        
        do {
            logger.debug("üîç Adicionando stream output...")
            try stream?.addStreamOutput(self, type: .audio, sampleHandlerQueue: DispatchQueue(label: "ScreenCaptureKit.AudioQueue"))
            
            logger.debug("üîç Iniciando stream...")
            try await stream?.startCapture()
            
            _isCapturing = true
            _isPaused = false
            
            logger.info("‚úÖ Captura ScreenCaptureKit iniciada")
            logger.info("ScreenCaptureKit: Stream iniciado com sucesso")
            
            // üîß DIAGN√ìSTICO: Agendar verifica√ß√£o
            Task {
                try await Task.sleep(nanoseconds: 3_000_000_000) // 3 segundos
                await self.diagnosticCheck()
            }
            
        } catch {
            logger.error("‚ùå Erro ao iniciar captura: \(error)")
            logger.error("ERRO ScreenCaptureKit: \(error)")
            throw SystemAudioCaptureError.captureStartFailed(error)
        }
    }
    
    // üîß DIAGN√ìSTICO: Verifica√ß√£o espec√≠fica do ScreenCaptureKit
    private func diagnosticCheck() async {
        logger.debug("üîç DIAGN√ìSTICO - ScreenCaptureKit (ap√≥s 3s):")
        logger.debug("   ‚Ä¢ Samples de √°udio recebidos: \(self.audioSamplesReceived)")
        logger.debug("   ‚Ä¢ Stream ativo: \(self._isCapturing)")
        logger.debug("   ‚Ä¢ Stream pausado: \(self._isPaused)")
        logger.debug("   ‚Ä¢ Stream objeto existe: \(self.stream != nil)")
        
        if self.audioSamplesReceived == 0 {
            logger.error("PROBLEMA: ScreenCaptureKit n√£o est√° recebendo √°udio!")
            logger.debug("üí° Verifica√ß√µes:")
            logger.debug("   ‚Ä¢ H√° √°udio sendo reproduzido no sistema?")
            logger.debug("   ‚Ä¢ As permiss√µes de ScreenCaptureKit foram concedidas?")
            logger.debug("   ‚Ä¢ O app est√° exclu√≠do em excludesCurrentProcessAudio?")
        } else {
            logger.info("ScreenCaptureKit funcionando corretamente!")
        }
        
        // Verifica√ß√£o cont√≠nua a cada 10 segundos
        if self._isCapturing {
            Task {
                try await Task.sleep(nanoseconds: 10_000_000_000) // 10 segundos
                await self.monitorStreamHealth()
            }
        }
    }
    
    // üîß NOVO: Monitoramento cont√≠nuo da sa√∫de do stream (baseado na pesquisa)
    private func monitorStreamHealth() async {
        let previousSampleCount = audioSamplesReceived
        let checkTime = Date()
        
        // üîß CR√çTICO: Reduzir tempo de detec√ß√£o para 3 segundos baseado nos dados do log
        // Log mostrou que stream congela completamente sem notificar erro
        try? await Task.sleep(nanoseconds: 3_000_000_000)
        
        if _isCapturing && audioSamplesReceived == previousSampleCount {
            let timeSinceLastSample = Date().timeIntervalSince(lastSampleTime)
            let elapsedTime = Date().timeIntervalSince(streamStartTime)
            
            // Log detalhado da detec√ß√£o de problema
            writeToDebugLog("STREAM_HEALTH_ISSUE: No samples for 5s at \(String(format: "%.3f", elapsedTime))s")
            writeToDebugLog("LAST_SAMPLE_TIME: \(String(format: "%.3f", timeSinceLastSample))s ago")
            writeToDebugLog("SAMPLES_FROZEN_AT: \(audioSamplesReceived)")
            
            logger.error("‚ùå STREAM CONGELADO: ScreenCaptureKit parou silenciosamente sem erro!")
            logger.warning("   ‚Ä¢ Samples antes: \(previousSampleCount)")
            logger.warning("   ‚Ä¢ Samples agora: \(audioSamplesReceived)")
            logger.warning("   ‚Ä¢ √öltimo sample h√°: \(String(format: "%.1f", timeSinceLastSample))s")
            logger.warning("   ‚Ä¢ Tempo total: \(String(format: "%.1f", elapsedTime))s")
            
            // üîß NOVA ESTRAT√âGIA: Baseada na descoberta do log - stream congela silenciosamente
            // Sempre tentar recupera√ß√£o quando detectar congelamento
            writeToDebugLog("STREAM_FROZEN_DETECTED: \(audioSamplesReceived) samples - IMMEDIATE RECOVERY NEEDED")
            logger.error("üö® CONGELAMENTO CONFIRMADO - Iniciando recupera√ß√£o imediata...")
            
            // Notificar sistema de fallback sobre stream congelado
            let frozenError = NSError(domain: "ScreenCaptureKit", code: -3808, 
                                     userInfo: [NSLocalizedDescriptionKey: "Stream frozen silently - no samples for 3+ seconds"])
            onStreamFailure?(frozenError)
            
            // Tentar recupera√ß√£o agressiva
            await attemptStreamRecovery()
            
            // Verificar se o stream ainda existe
            if stream != nil {
                logger.debug("   ‚Ä¢ Stream objeto ainda existe")
                writeToDebugLog("STREAM_OBJECT: Still exists")
            } else {
                logger.error("   ‚Ä¢ ‚ùå Stream objeto foi perdido!")
                writeToDebugLog("STREAM_OBJECT: Lost/nil")
                _isCapturing = false
            }
        } else if _isCapturing {
            // Stream ainda saud√°vel
            let elapsedTime = Date().timeIntervalSince(streamStartTime)
            writeToDebugLog("STREAM_HEALTHY: \(audioSamplesReceived) samples at \(String(format: "%.3f", elapsedTime))s")
        }
        
        // Continuar monitoramento se ainda capturando
        if _isCapturing {
            Task {
                try await Task.sleep(nanoseconds: 10_000_000_000) // 10 segundos
                await self.monitorStreamHealth()
            }
        }
    }
    
    // üîß NOVA: Tentativa de recupera√ß√£o autom√°tica do stream
    private func attemptStreamRecovery() async {
        logger.info("üîÑ Iniciando recupera√ß√£o autom√°tica do ScreenCaptureKit...")
        
        guard let currentStream = stream else {
            logger.error("‚ùå N√£o √© poss√≠vel recuperar: stream √© nil")
            return
        }
        
        do {
            // Parar o stream atual
            logger.debug("üîÑ Parando stream atual...")
            try await currentStream.stopCapture()
            
            // Aguardar um pouco para o sistema liberar recursos
            try await Task.sleep(nanoseconds: 1_000_000_000) // 1 segundo
            
            // Obter novo conte√∫do (pode ter mudado)
            logger.debug("üîÑ Obtendo novo conte√∫do compartilh√°vel...")
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            
            guard let display = content.displays.first else {
                logger.error("‚ùå Nenhum display encontrado na recupera√ß√£o")
                _isCapturing = false
                return
            }
            
            // Criar nova configura√ß√£o (pode resolver bugs conhecidos)
            let filter = SCContentFilter(display: display, excludingApplications: [], exceptingWindows: [])
            let config = SCStreamConfiguration()
            config.capturesAudio = true
            config.excludesCurrentProcessAudio = true
            config.sampleRate = 48000 // Usar padr√£o conhecido funcional
            config.channelCount = 2
            
            // Configura√ß√µes otimizadas para estabilidade
            config.width = 2
            config.height = 2
            config.minimumFrameInterval = CMTime(value: 1, timescale: 1)
            config.showsCursor = false
            config.scalesToFit = false
            
            // Criar novo stream
            let newStream = SCStream(filter: filter, configuration: config, delegate: self)
            
            // Configurar output
            try newStream.addStreamOutput(self, type: .audio, sampleHandlerQueue: DispatchQueue(label: "ScreenCaptureKit.AudioQueue.Recovery"))
            
            // Iniciar novo stream
            try await newStream.startCapture()
            
            // Substitir stream antigo
            stream = newStream
            
            logger.info("‚úÖ Recupera√ß√£o do ScreenCaptureKit bem-sucedida")
            
        } catch {
            logger.error("‚ùå Falha na recupera√ß√£o autom√°tica: \(error)")
            _isCapturing = false
        }
    }
    
    func stopCapture() async {
        logger.info("üõë Parando captura ScreenCaptureKit...")
        
        // üîß DIAGN√ìSTICO: Log final com estat√≠sticas completas
        let totalTime = Date().timeIntervalSince(streamStartTime)
        let timeSinceLastSample = Date().timeIntervalSince(lastSampleTime)
        
        writeToDebugLog("STOP_CAPTURE: Total time \(String(format: "%.3f", totalTime))s, Last sample \(String(format: "%.3f", timeSinceLastSample))s ago")
        writeToDebugLog("FINAL_STATS: \(audioSamplesReceived) total samples")
        
        logger.info("üìä Estat√≠sticas finais ScreenCaptureKit:")
        logger.info("   ‚Ä¢ Total de samples: \(audioSamplesReceived)")
        logger.info("   ‚Ä¢ Tempo total: \(String(format: "%.1f", totalTime))s")
        logger.info("   ‚Ä¢ √öltimo sample h√°: \(String(format: "%.1f", timeSinceLastSample))s")
        
        _isCapturing = false
        _isPaused = false
        
        if let stream = stream {
            do {
                try await stream.stopCapture()
                self.stream = nil
                logger.info("‚úÖ Captura ScreenCaptureKit parada")
                writeToDebugLog("STREAM_STOPPED: Successfully")
            } catch {
                logger.error("‚ùå Erro ao parar captura: \(error)")
                writeToDebugLog("STREAM_STOP_ERROR: \(error)")
            }
        }
        
        // Fechar arquivo de log
        closeDebugLogging()
    }
    
    func pauseCapture() async {
        guard _isCapturing && !_isPaused else { return }
        
        _isPaused = true
        // ScreenCaptureKit n√£o tem pause nativo, precisamos parar callbacks
        logger.info("‚è∏Ô∏è Captura ScreenCaptureKit pausada")
        logger.debug("‚è∏Ô∏è ScreenCaptureKit pausado")
    }
    
    func resumeCapture() async {
        guard _isCapturing && _isPaused else { return }
        
        _isPaused = false
        logger.info("‚ñ∂Ô∏è Captura ScreenCaptureKit retomada")
        logger.debug("‚ñ∂Ô∏è ScreenCaptureKit retomado")
    }
    
    // MARK: - SystemAudioCaptureProtocol Methods
    
    func requestSystemPermissions() async -> Bool {
        guard isSystemAudioSupported else {
            logger.warning("‚ùå Sistema n√£o suporta ScreenCaptureKit")
            return false
        }
        
        do {
            _ = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("‚úÖ Permiss√µes ScreenCaptureKit concedidas")
            logger.info("Permiss√µes ScreenCaptureKit: OK")
            return true
        } catch {
            logger.error("‚ùå Erro de permiss√£o ScreenCaptureKit: \(error)")
            logger.error("ERRO de permiss√£o ScreenCaptureKit: \(error)")
            return false
        }
    }
    
    func getSystemAudioCapabilities() -> SystemAudioCapabilities {
        let osVersion = ProcessInfo.processInfo.operatingSystemVersion
        
        let strategy: AudioCaptureStrategy
        if osVersion.majorVersion >= 14 && osVersion.minorVersion >= 2 {
            strategy = .coreAudioTaps
        } else if osVersion.majorVersion >= 13 {
            strategy = .screenCaptureKit
        } else {
            strategy = .microphoneOnly
        }
        
        return SystemAudioCapabilities(
            isSupported: isSystemAudioSupported,
            supportedStrategy: strategy,
            macOSVersion: "\(osVersion.majorVersion).\(osVersion.minorVersion).\(osVersion.patchVersion)",
            recommendedConfiguration: isSystemAudioSupported ? .mixed : .microphoneOnly
        )
    }
    
    func isSystemAudioAvailable() async -> Bool {
        // Verificar suporte do sistema operacional
        guard isSystemAudioSupported else {
            logger.warning("‚ùå Sistema n√£o suporta captura de √°udio do sistema")
            logger.error("Sistema n√£o suporta ScreenCaptureKit")
            return false
        }
        
        // Verificar permiss√µes
        guard await requestSystemPermissions() else {
            logger.warning("‚ùå Permiss√µes para ScreenCaptureKit n√£o concedidas")
            return false
        }
        
        // Em sistemas mais recentes, podemos verificar a disponibilidade
        // Por enquanto, se o sistema suporta e temos permiss√£o, assumimos dispon√≠vel
        // Isso ser√° detectado durante a captura de qualquer forma
        
        // Se ScreenCaptureKit est√° dispon√≠vel e permitido, presumimos que o √°udio do sistema
        // tamb√©m est√° dispon√≠vel at√© prova em contr√°rio (durante a captura)
        let hasAudioSources = true
        
        logger.info("üîä √Åudio do sistema presumido dispon√≠vel via ScreenCaptureKit: \(hasAudioSources ? "‚úÖ" : "‚ùå")")
        logger.debug("üîä √Åudio do sistema dispon√≠vel: Presumido Sim")
        
        return hasAudioSources
    }
    
    // MARK: - SCStreamOutput
    
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .audio, !_isPaused else { return }
        
        // üîß DIAGN√ìSTICO: Contar samples e registrar timing preciso
        audioSamplesReceived += 1
        let now = Date()
        lastSampleTime = now
        let elapsedTime = now.timeIntervalSince(streamStartTime)
        
        // Log detalhado para arquivo
        writeToDebugLog("SAMPLE_\(audioSamplesReceived): \(String(format: "%.3f", elapsedTime))s")
        
        if audioSamplesReceived == 1 {
            logger.debug("üéµ PRIMEIRO sample de √°udio ScreenCaptureKit recebido!")
            writeToDebugLog("FIRST_SAMPLE: \(String(format: "%.3f", elapsedTime))s")
            
            // Log detalhado do primeiro sample
            if let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer),
               let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) {
                logger.debug("   ‚Ä¢ Sample Rate: \(audioStreamBasicDescription.pointee.mSampleRate)Hz")
                logger.debug("   ‚Ä¢ Canais: \(audioStreamBasicDescription.pointee.mChannelsPerFrame)")
                logger.debug("   ‚Ä¢ Frames: \(CMSampleBufferGetNumSamples(sampleBuffer))")
                
                writeToDebugLog("FORMAT: \(audioStreamBasicDescription.pointee.mSampleRate)Hz, \(audioStreamBasicDescription.pointee.mChannelsPerFrame)ch")
            }
        }
        
        // üîß DIAGN√ìSTICO: Log a cada 1000 samples para monitorar continuidade
        if audioSamplesReceived % 1000 == 0 {
            logger.debug("üîç ScreenCaptureKit: \(audioSamplesReceived) samples de √°udio recebidos (tempo: \(String(format: "%.1f", elapsedTime))s)")
            writeToDebugLog("MILESTONE_1000: \(audioSamplesReceived) samples at \(String(format: "%.3f", elapsedTime))s")
        }
        
        guard let audioBuffer = createAudioBuffer(from: sampleBuffer) else {
            logger.warning("‚ö†Ô∏è Falha ao criar buffer de √°udio")
            logger.warning("üîç DIAGN√ìSTICO: Sample \(audioSamplesReceived) falhou na convers√£o")
            return
        }
        
        let hostTime = mach_absolute_time()
        onAudioReceived?(audioBuffer, hostTime)
    }
    
    // MARK: - SCStreamDelegate
    
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        logger.error("‚ùå Stream parou com erro: \(error)")
        logger.error("ScreenCaptureKit stream erro: \(error)")
        logger.error("üîç DIAGN√ìSTICO - Stream parou inesperadamente:")
        logger.error("   ‚Ä¢ Total de samples recebidos: \(audioSamplesReceived)")
        logger.error("   ‚Ä¢ Era capturando: \(_isCapturing)")
        logger.error("   ‚Ä¢ Estava pausado: \(_isPaused)")
        logger.error("   ‚Ä¢ Tipo do erro: \(type(of: error))")
        logger.error("   ‚Ä¢ Descri√ß√£o completa: \(error.localizedDescription)")
        
        // Log informa√ß√µes do sistema
        let memoryPressure = ProcessInfo.processInfo.thermalState
        logger.error("   ‚Ä¢ Estado t√©rmico: \(memoryPressure.rawValue)")
        
        _isCapturing = false
        _isPaused = false
        
        // üîß NOVO: Notificar falha para o sistema de fallback
        onStreamFailure?(error)
    }
    
    // MARK: - Helper Methods
    
    private func createAudioBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        // Obter o formato de √°udio do sample buffer
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer),
              let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription),
              let format = AVAudioFormat(streamDescription: audioStreamBasicDescription) else {
            return nil
        }
        
        // Obter o n√∫mero de frames
        let frameLength = CMSampleBufferGetNumSamples(sampleBuffer)
        
        // Criar buffer PCM
        guard let audioBuffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameLength)) else {
            return nil
        }
        
        audioBuffer.frameLength = AVAudioFrameCount(frameLength)
        
        // Copiar dados de √°udio usando Core Media
        let audioBufferListPtr = audioBuffer.mutableAudioBufferList
        
        let status = CMSampleBufferCopyPCMDataIntoAudioBufferList(
            sampleBuffer,
            at: 0,
            frameCount: Int32(frameLength),
            into: audioBufferListPtr
        )
        
        guard status == noErr else {
            logger.warning("‚ö†Ô∏è Erro ao copiar dados PCM: \(status)")
            return nil
        }
        
        return audioBuffer
    }
    
    // MARK: - Debug Logging
    
    private func setupDebugLogging() {
        let timestamp = ISO8601DateFormatter().string(from: Date())
        let logFileName = "screencapturekit_debug_\(timestamp).log"
        let logURL = URL(fileURLWithPath: "/tmp/\(logFileName)")
        
        do {
            // Criar arquivo se n√£o existir
            if !FileManager.default.fileExists(atPath: logURL.path) {
                FileManager.default.createFile(atPath: logURL.path, contents: nil)
            }
            
            logFile = try FileHandle(forWritingTo: logURL)
            logFile?.seekToEndOfFile()
            
            writeToDebugLog("SESSION_START: \(timestamp)")
            writeToDebugLog("LOG_FILE: \(logURL.path)")
            
            logger.info("üîß Debug logging iniciado: \(logURL.path)")
            
        } catch {
            logger.error("‚ùå Falha ao criar arquivo de debug: \(error)")
        }
    }
    
    private func writeToDebugLog(_ message: String) {
        guard let logFile = logFile else { return }
        
        let timestamp = String(format: "%.3f", Date().timeIntervalSince(streamStartTime))
        let logEntry = "[\(timestamp)s] \(message)\n"
        
        if let data = logEntry.data(using: .utf8) {
            logFile.write(data)
        }
    }
    
    private func closeDebugLogging() {
        writeToDebugLog("SESSION_END: \(ISO8601DateFormatter().string(from: Date()))")
        
        logFile?.closeFile()
        logFile = nil
        
        // Log localiza√ß√£o do arquivo final
        if let logPath = logFile?.fileDescriptor {
            logger.info("üîß Debug log finalizado. Arquivo salvo para an√°lise.")
        }
    }
}

enum ScreenCaptureKitError: Error {
    case permissionDenied
    case configurationFailed
} 